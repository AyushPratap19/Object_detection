<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Attendance System using Face Detection</title>
    <style>
       body {
            font-family: Arial, sans-serif;
            text-align: center;
            margin: 20px;
        }

        .left-image,
        .right-image {
            position: absolute;
            margin-top: 300px;
            margin-right: 200px;
            top: 0;
            height: 200px;
            /* Adjust the height as needed */
        }

        .left-image {
            left: 0;
            width: 150px;
            margin-left: 200px;
        }

        .right-image {
            right: 0;
            width: 150px;
        }

        .container {
            max-width: 1000px;
            margin: 0 auto;
            display: flex;
            flex-direction: column; /* Arrange elements in a column */
            align-items: center; /* Center elements horizontally */
        }

        h1 {
            margin-bottom: 20px;
        }

        h3 {
            margin-bottom: 20px;
            color: rgb(235, 98, 7);
        }

        .camera-feed {
            margin-bottom: 20px;
            position: relative; /* Ensure the video element is positioned relative to the container */
        }

        #webcam-video {
            border: 5px solid #0b051a;
            display: block;
            margin: 0 auto;
            position: relative; /* Position the video element within the container */
            width: 600px;
            height: 450px;
        }

        #detection-canvas {
            position:absolute;
            top: 0;
            left: 0;
            right: 100;
            bottom: 100;
            transform: scale(var(--scale,1)); /* Scale the canvas to match the video dimensions */
            transform-origin:center;
        }

        .camera-buttons {
            margin-top: 100px;
            display: flex;
            justify-content: center; 
            flex-wrap: wrap;
        }

        button {
            margin: 10px;
            padding: 10px 20px;
            font-size: 16px;
            background-color: #4CAF50;
            color: white;
            border: none;
            cursor: pointer;
        }

        .output {
            margin-top: 15px;
            border: 5px solid #acaa26;
            padding: 20px;
            text-align: left;
            max-height: 5px;
            overflow-y:auto;
            width: 500px;
        }

    </style>
</head>
<body>
    <img src="https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcR3B_7T4WKY6jTFSAjpGR7ohutCq3Rbm2S34A&usqp=CAU" alt="Left Image" class="left-image">
    <img src="https://www.powerschool.com/wp-content/uploads/2016/09/line-14-img-8-300x300-1.png" alt="Right Image" height ="50" class="right-image">
    <div class="container">
        <img src="https://images.collegedunia.com/public/college_data/images/logos/1626679401rnsitlOGO.png" alt="logo" height ="50">
        <h1> RNS Institute Of Technology</h1>
        
        <h3>Attendance System using Face Detection</h3>
        <div class="camera-feed">
            <video id="webcam-video" width="600" height="450" autoplay playsinline></video>
        </div>
        <button id="start-btn">Start Detection</button>
        <button id="stop-btn">Stop Detection</button>
        <div class="output">
            <!-- Output results, like recognized faces and attendance data, can be shown here -->
        </div>
    </div>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/coco-ssd"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/coco-ssd"></script>
    <script>
        async function startWebcamAndDetectObjects() {
            try {
                const videoElement = document.getElementById('webcam-video');
                const canvasElement = document.createElement('canvas');
                canvasElement.id = 'detection-canvas';
                const ctx = canvasElement.getContext('2d');
                document.body.appendChild(canvasElement);

                const model = await cocoSsd.load();

                const stream = await navigator.mediaDevices.getUserMedia({
                    audio: false,
                    video: true
                });
                videoElement.srcObject = stream;

                await new Promise((resolve) => {
                    videoElement.onloadedmetadata = () => {
                        resolve();
                    };
                });

                // Set canvas dimensions to match the video dimensions
                canvasElement.width = videoElement.videoWidth;
                canvasElement.height = videoElement.videoHeight;

                // Perform object detection every 100 milliseconds
                setInterval(async () => {
                    // Detect objects in the video frame
                    const predictions = await model.detect(videoElement);

                    // Clear the canvas
                    ctx.clearRect(0, 0, canvasElement.width, canvasElement.height);

                    // Draw bounding boxes and labels for detected objects
                    predictions.forEach(prediction => {
                        const [x, y, width, height] = prediction.bbox;
                        // Adjust the coordinates based on the position of the video element
                        const adjustedX = x + videoElement.offsetLeft;
                        const adjustedY = y + videoElement.offsetTop;
                        ctx.beginPath();
                        ctx.rect(adjustedX, adjustedY, width, height);
                        ctx.strokeStyle = 'red';
                        ctx.lineWidth = 2;
                        ctx.stroke();
                        ctx.fillStyle = 'red';
                        ctx.font = '16px Arial';
                        ctx.fillText(prediction.class, adjustedX, adjustedY - 5);
                    });
                }, 100); // You can adjust the interval as needed
            } catch (error) {
                console.error('Error accessing webcam:', error);
            }
        }

        startWebcamAndDetectObjects();
        const webcamVideoElement = document.getElementById("webcam-video");
        const startButton = document.getElementById("start-btn");
        const stopButton = document.getElementById("stop-btn");
        const outputDiv = document.querySelector(".output");

        let isDetecting = false;
        let webcamStream = null;

        // Function to start face detection and open the camera
        async function startDetection() {
            try {
                webcamStream = await navigator.mediaDevices.getUserMedia({ video: true });
                webcamVideoElement.srcObject = webcamStream;
                webcamVideoElement.play();
                isDetecting = true;
                outputDiv.innerHTML = "Face detection started.";
            } catch (err) {
                console.error("Error accessing the camera:", err);
                outputDiv.innerHTML = "Error accessing the camera. Please check your permissions.";
            }
        }

        // Function to stop face detection and close the camera
        function stopDetection() {
            if (webcamStream) {
                webcamStream.getTracks().forEach(track => track.stop());
                webcamVideoElement.srcObject = null;
            }
            isDetecting = false;
            outputDiv.innerHTML = "Face detection stopped.";
        }

        startButton.addEventListener("click", startDetection);
        stopButton.addEventListener("click", stopDetection);
    </script>
</body>


</body>
</html>